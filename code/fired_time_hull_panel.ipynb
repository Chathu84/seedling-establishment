{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0f8db2d",
   "metadata": {},
   "source": [
    "# FIRED Daily Vertical Time-Hull Panel\n",
    "\n",
    "This notebook contains the shared sample code for building minimalist FIRED daily vertical time-hull panels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c05279",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "FIRED Daily — Minimalist Vertical Time‑Hull Panel\n",
    "(Volume‑sorted + Surface Area + OT Velocity, PNG/PDF + CSV outputs)\n",
    "-------------------------------------------------------------------\n",
    "\n",
    "This script takes a FIRED-style **daily perimeter GeoDataFrame** and produces a\n",
    "minimalist panel of 3D ruled time‑hulls (one hull per event), together with a\n",
    "per‑event summary table and (optionally) a per‑interval optimal‑transport (OT)\n",
    "velocity table.\n",
    "\n",
    "What it does\n",
    "============\n",
    "1) **Cleans** the daily polygons per event (sorts by date, merges multipolygons,\n",
    "   drops consecutive duplicate geometries).\n",
    "2) **Builds a 3D ruled hull** over time using support‑function slices sampled\n",
    "   uniformly around the ring for each day.\n",
    "3) **Computes per‑event metrics**:\n",
    "   - `space`   : max horizontal radius of the hull (km)\n",
    "   - `time`    : cleaned day count (days)\n",
    "   - `volume`  : ∫ area(t) dt across cleaned days (km²·days)\n",
    "   - `surface` : surface area of the ruled hull (km·days)\n",
    "   - `SA/V`    : surface‑to‑volume ratio (1/km)\n",
    "   - `OT v̄`   : mean OT RMS speed between consecutive days (km/day)\n",
    "4) **Saves outputs**:\n",
    "   - **Plots**: multi‑page **PDF** and per‑page **PNG** (transparent)\n",
    "   - **CSV**: per‑event summary and (optionally) per‑interval OT series\n",
    "5) **Displays a compact panel** with four short label lines under each hull.\n",
    "   (Units are **suppressed by default**; can be toggled on.)\n",
    "\n",
    "Defaults you asked for\n",
    "======================\n",
    "- **Ordering**: by **volume ascending** (smaller top‑left → larger bottom‑right).\n",
    "- **Labels**: moved higher and **reordered** to: volume → OT speed → space → time.\n",
    "\n",
    "Inputs expected\n",
    "===============\n",
    "A GeoDataFrame named `gdf_daily` with at least the following columns:\n",
    "- `id` (event id), `date` (datetime), `event_day` (1..N optional but helpful),\n",
    "- `duration` (summary duration in days), `total_area_km2` (summary area),\n",
    "- `geometry` (daily polygon/multipolygon perimeter for that date).\n",
    "\n",
    "You may also call `plot_hull_panel_minimal(...)` directly with your GeoDataFrame.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple, Optional\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Polygon, MultiPolygon, LineString, Point\n",
    "from shapely.ops import unary_union\n",
    "from shapely.prepared import prep\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# =============================================================================\n",
    "# Cleaning & geometry helpers\n",
    "# =============================================================================\n",
    "\n",
    "def clean_event_daily_rows(\n",
    "    gdf_daily: gpd.GeoDataFrame,\n",
    "    event_id,\n",
    "    id_col: str = \"id\",\n",
    "    date_col: str = \"date\",\n",
    ") -> Optional[gpd.GeoDataFrame]:\n",
    "    \"\"\"Return a cleaned, sorted per‑day GeoDataFrame for one event.\n",
    "\n",
    "    Steps\n",
    "    -----\n",
    "    1) Subset by id\n",
    "    2) Coerce/sort dates\n",
    "    3) Merge MultiPolygons\n",
    "    4) Drop consecutive duplicate geometries\n",
    "    \"\"\"\n",
    "    eg = gdf_daily[gdf_daily[id_col] == event_id].copy()\n",
    "    if eg.empty:\n",
    "        return None\n",
    "    eg[date_col] = pd.to_datetime(eg[date_col], errors=\"coerce\")\n",
    "    eg = eg.sort_values(date_col)\n",
    "\n",
    "    rows, last_geom = [], None\n",
    "    for _, r in eg.iterrows():\n",
    "        g = r.geometry\n",
    "        if g is None or g.is_empty:\n",
    "            continue\n",
    "        try:\n",
    "            if g.geom_type == \"MultiPolygon\":\n",
    "                g = unary_union(g)\n",
    "        except Exception:\n",
    "            pass\n",
    "        if last_geom is not None and g.equals(last_geom):\n",
    "            continue\n",
    "        r = r.copy(); r.geometry = g\n",
    "        rows.append(r); last_geom = g\n",
    "\n",
    "    if not rows:\n",
    "        return None\n",
    "    return gpd.GeoDataFrame(rows, crs=gdf_daily.crs).reset_index(drop=True)\n",
    "\n",
    "\n",
    "def _largest_polygon(geom) -> Optional[Polygon]:\n",
    "    \"\"\"Return the largest Polygon from a (Multi)Polygon geometry.\"\"\"\n",
    "    if geom is None or geom.is_empty:\n",
    "        return None\n",
    "    if isinstance(geom, Polygon):\n",
    "        return geom\n",
    "    if isinstance(geom, MultiPolygon):\n",
    "        polys = [p for p in geom.geoms if isinstance(p, Polygon)]\n",
    "        return max(polys, key=lambda p: p.area) if polys else None\n",
    "    return None\n",
    "\n",
    "\n",
    "def _sample_ring_equal_steps(poly: Polygon, n_samples: int = 100) -> Optional[np.ndarray]:\n",
    "    \"\"\"Sample `n_samples` points along the polygon exterior at equal arc‑length steps.\"\"\"\n",
    "    if poly is None or poly.is_empty:\n",
    "        return None\n",
    "    ring = LineString(poly.exterior.coords)\n",
    "    if ring.coords and ring.coords[0] == ring.coords[-1]:  # drop duplicate closer\n",
    "        ring = LineString(list(ring.coords)[:-1])\n",
    "    L = ring.length\n",
    "    if not np.isfinite(L) or L <= 0:\n",
    "        return None\n",
    "    s = np.linspace(0, L, n_samples, endpoint=False)\n",
    "    pts = np.array([ring.interpolate(d).coords[0] for d in s], float)\n",
    "    return pts if np.all(np.isfinite(pts)) else None\n",
    "\n",
    "# =============================================================================\n",
    "# OT helpers (uniform mass grids + entropic Sinkhorn W2^2)\n",
    "# =============================================================================\n",
    "\n",
    "def _poly_to_grid_masses(poly: Polygon, bounds: Tuple[float, float, float, float], res_m: float = 1000.0):\n",
    "    \"\"\"Discretize polygon to uniform masses over a regular grid of cell centers.\n",
    "    Returns (XY, w) with masses normalized to 1; (None, None) if no cells inside.\n",
    "    \"\"\"\n",
    "    minx, miny, maxx, maxy = bounds\n",
    "    nx = max(1, int(np.ceil((maxx - minx) / res_m)))\n",
    "    ny = max(1, int(np.ceil((maxy - miny) / res_m)))\n",
    "    xs = minx + (np.arange(nx) + 0.5) * ((maxx - minx) / nx)\n",
    "    ys = miny + (np.arange(ny) + 0.5) * ((maxy - miny) / ny)\n",
    "    XX, YY = np.meshgrid(xs, ys, indexing=\"xy\")\n",
    "    centers = np.column_stack([XX.ravel(), YY.ravel()])\n",
    "    pp = prep(poly)\n",
    "    mask = np.fromiter((pp.contains(Point(xy)) for xy in centers), count=len(centers), dtype=bool)\n",
    "    XY_in = centers[mask]\n",
    "    if XY_in.size == 0:\n",
    "        return None, None\n",
    "    w = np.full(len(XY_in), 1.0 / len(XY_in), dtype=float)\n",
    "    return XY_in, w\n",
    "\n",
    "\n",
    "def _sinkhorn_distance_squared(X: np.ndarray, a: np.ndarray, Y: np.ndarray, b: np.ndarray,\n",
    "                               *, epsilon: float = 2000.0, n_iter: int = 200) -> float:\n",
    "    \"\"\"Entropic OT with squared Euclidean cost. Returns W2^2 in meters².\"\"\"\n",
    "    C = np.sum(X**2, axis=1)[:, None] + np.sum(Y**2, axis=1)[None, :] - 2.0 * (X @ Y.T)\n",
    "    K = np.exp(-C / epsilon)\n",
    "    K = np.maximum(K, 1e-300)\n",
    "    u = np.ones_like(a); v = np.ones_like(b)\n",
    "    a = np.asarray(a, float); b = np.asarray(b, float)\n",
    "    for _ in range(n_iter):\n",
    "        u = a / (K @ v + 1e-300)\n",
    "        v = b / (K.T @ u + 1e-300)\n",
    "    T = (u[:, None] * K) * v[None, :]\n",
    "    T_sum = T.sum()\n",
    "    if not np.isfinite(T_sum) or T_sum <= 0:\n",
    "        return np.nan\n",
    "    T /= T_sum\n",
    "    return float((T * C).sum())\n",
    "\n",
    "\n",
    "def compute_ot_velocity_series(\n",
    "    eg_clean: gpd.GeoDataFrame,\n",
    "    *,\n",
    "    crs_epsg: int = 5070,\n",
    "    date_col: str = \"date\",\n",
    "    z_col: str = \"event_day\",\n",
    "    grid_res_m: float = 1000.0,\n",
    "    epsilon: float = 2000.0,\n",
    "    n_iter: int = 200,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Per‑interval OT velocity between consecutive daily polygons.\n",
    "\n",
    "    Returns columns: ['id','t0','t1','day0','day1','ot_w2_km2','ot_speed_km_per_day']\n",
    "    \"\"\"\n",
    "    if eg_clean is None or len(eg_clean) < 2:\n",
    "        return pd.DataFrame(columns=[\"id\",\"t0\",\"t1\",\"day0\",\"day1\",\"ot_w2_km2\",\"ot_speed_km_per_day\"])\n",
    "\n",
    "    g = eg_clean.copy()\n",
    "    g[date_col] = pd.to_datetime(g[date_col], errors=\"coerce\")\n",
    "    g = g.sort_values(date_col).reset_index(drop=True)\n",
    "    if crs_epsg is not None:\n",
    "        try: g = g.to_crs(epsg=crs_epsg)\n",
    "        except Exception: pass\n",
    "\n",
    "    # Shared bbox for consistent grids\n",
    "    bbox = None; polys = []\n",
    "    for geom in g.geometry:\n",
    "        poly = geom if isinstance(geom, Polygon) else _largest_polygon(geom)\n",
    "        polys.append(poly)\n",
    "        if poly is not None:\n",
    "            b = poly.bounds\n",
    "            bbox = b if bbox is None else (min(bbox[0], b[0]), min(bbox[1], b[1]),\n",
    "                                           max(bbox[2], b[2]), max(bbox[3], b[3]))\n",
    "    if bbox is None:\n",
    "        return pd.DataFrame(columns=[\"id\",\"t0\",\"t1\",\"day0\",\"day1\",\"ot_w2_km2\",\"ot_speed_km_per_day\"])\n",
    "\n",
    "    grids = [(_poly_to_grid_masses(p, bbox, res_m=grid_res_m) if p is not None else (None, None)) for p in polys]\n",
    "\n",
    "    rows = []\n",
    "    for i in range(len(g)-1):\n",
    "        idv  = g.loc[i, \"id\"] if \"id\" in g.columns else np.nan\n",
    "        t0, t1 = g.loc[i, date_col], g.loc[i+1, date_col]\n",
    "        d0 = int(g.loc[i, z_col]) if z_col in g.columns else i+1\n",
    "        d1 = int(g.loc[i+1, z_col]) if z_col in g.columns else i+2\n",
    "        dt_days = max(1e-9, (t1 - t0).days if pd.notnull(t0) and pd.notnull(t1) else (d1 - d0))\n",
    "\n",
    "        X, a = grids[i]; Y, b = grids[i+1]\n",
    "        if X is None or Y is None:\n",
    "            w2_km2 = np.nan; v_km_day = np.nan\n",
    "        else:\n",
    "            w2_m2 = _sinkhorn_distance_squared(X, a, Y, b, epsilon=epsilon, n_iter=n_iter)\n",
    "            w2_km2 = w2_m2 / 1e6\n",
    "            v_km_day = np.sqrt(max(0.0, w2_km2)) / dt_days\n",
    "\n",
    "        rows.append({\n",
    "            \"id\": float(idv) if pd.notnull(idv) else np.nan,\n",
    "            \"t0\": t0, \"t1\": t1, \"day0\": d0, \"day1\": d1,\n",
    "            \"ot_w2_km2\": w2_km2, \"ot_speed_km_per_day\": v_km_day\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# =============================================================================\n",
    "# 3D ruled hull drawing + metrics (adds surface area)\n",
    "# =============================================================================\n",
    "\n",
    "def _tri_area(p: np.ndarray, q: np.ndarray, r: np.ndarray) -> float:\n",
    "    \"\"\"Area of triangle defined by 3D points p,q,r via 0.5*|| (q-p)×(r-p) ||.\"\"\"\n",
    "    return 0.5 * np.linalg.norm(np.cross(q - p, r - p))\n",
    "\n",
    "\n",
    "def draw_ruled_time_hull_minimal(\n",
    "    ax,\n",
    "    eg_clean: gpd.GeoDataFrame,\n",
    "    *,\n",
    "    date_col: str = \"date\",\n",
    "    z_col: str = \"event_day\",\n",
    "    n_ring_samples: int = 100,\n",
    "    n_theta: int = 96,\n",
    "    center_each_day: bool = True,\n",
    "    crs_epsg: int = 5070,\n",
    "    hull_color: str = \"firebrick\",\n",
    "    hull_alpha: float = 0.70,\n",
    "    edge_alpha: float = 0.08,\n",
    "    elev: float = 20,\n",
    "    azim: float = -55,\n",
    "    pad_frac: float = 0.03,\n",
    ") -> Tuple[bool, float, int, float, float]:\n",
    "    \"\"\"Draw one event's vertical ruled time‑hull on a 3D axis.\n",
    "\n",
    "    Returns (ok, scale_km, days, hull_volume_km2_days, hull_surface_km_day).\n",
    "    \"\"\"\n",
    "    ax.set_axis_off()\n",
    "    try:\n",
    "        ax.set_facecolor(\"none\")\n",
    "        ax.xaxis.pane.set_alpha(0.0); ax.yaxis.pane.set_alpha(0.0); ax.zaxis.pane.set_alpha(0.0)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    eg = eg_clean.copy()\n",
    "    eg[date_col] = pd.to_datetime(eg[date_col], errors=\"coerce\")\n",
    "    eg = eg.sort_values(date_col).reset_index(drop=True)\n",
    "    Z = eg[z_col].to_numpy(float) if z_col in eg.columns else np.arange(1, len(eg)+1, float)\n",
    "\n",
    "    if crs_epsg is not None:\n",
    "        try: eg = eg.to_crs(epsg=crs_epsg)\n",
    "        except Exception: pass\n",
    "\n",
    "    rings = []; areas_m2 = []\n",
    "    for g in eg.geometry:\n",
    "        poly = _largest_polygon(g)\n",
    "        if poly is None: continue\n",
    "        areas_m2.append(float(poly.area))\n",
    "        xy = _sample_ring_equal_steps(poly, n_ring_samples)\n",
    "        if xy is None: continue\n",
    "        if center_each_day: xy = xy - xy.mean(axis=0)\n",
    "        rings.append(xy)\n",
    "\n",
    "    if len(rings) < 2:\n",
    "        return False, np.nan, 0, 0.0, 0.0\n",
    "\n",
    "    thetas = np.linspace(0, 2*np.pi, n_theta, endpoint=False)\n",
    "    U = np.stack([np.cos(thetas), np.sin(thetas)], axis=1)\n",
    "    M, T = len(rings), n_theta\n",
    "\n",
    "    # Support radii per day\n",
    "    R = np.zeros((M, T), float)\n",
    "    for i, xy in enumerate(rings):\n",
    "        R[i, :] = (U @ xy.T).max(axis=1)\n",
    "\n",
    "    # 3D points in meters for rendering; z in days\n",
    "    P = np.zeros((M, T, 3), float)\n",
    "    P[:, :, 0] = R * U[None, :, 0]\n",
    "    P[:, :, 1] = R * U[None, :, 1]\n",
    "    P[:, :, 2] = np.array(Z[:M], float)[:, None]\n",
    "\n",
    "    # Same points in (km, km, day) for surface computation\n",
    "    PK = np.empty_like(P)\n",
    "    PK[:, :, 0] = P[:, :, 0] / 1000.0\n",
    "    PK[:, :, 1] = P[:, :, 1] / 1000.0\n",
    "    PK[:, :, 2] = P[:, :, 2]\n",
    "\n",
    "    # Metrics: scale & days\n",
    "    rmax = float(np.nanmax(np.sqrt(P[:, :, 0]**2 + P[:, :, 1]**2)))\n",
    "    scale_km = rmax / 1000.0\n",
    "    days = M\n",
    "\n",
    "    # Volume (km²·days)\n",
    "    Z_use = np.array(Z[:M], float)\n",
    "    areas_use = np.array(areas_m2[:M], float)\n",
    "    hull_volume_m2_days = np.trapz(areas_use, Z_use) if len(Z_use) >= 2 else 0.0\n",
    "    hull_volume_km2_days = hull_volume_m2_days / 1e6\n",
    "\n",
    "    # Mesh + surface area (sum of triangle areas in (km,km,day) space)\n",
    "    quads = []\n",
    "    surface = 0.0\n",
    "    for i in range(M - 1):\n",
    "        for j in range(T):\n",
    "            jn = (j + 1) % T\n",
    "            v1, v2, v3, v4 = PK[i, j], PK[i, jn], PK[i+1, jn], PK[i+1, j]\n",
    "            if np.all(np.isfinite([v1, v2, v3, v4])):\n",
    "                surface += _tri_area(v1, v2, v3) + _tri_area(v1, v3, v4)\n",
    "                quads.append([P[i, j], P[i, jn], P[i+1, jn], P[i+1, j]])\n",
    "\n",
    "    hull_surface_km_day = float(surface)\n",
    "\n",
    "    # Draw in meter space for correct depth sorting\n",
    "    coll = Poly3DCollection(\n",
    "        quads,\n",
    "        facecolors=plt.matplotlib.colors.to_rgba(hull_color, hull_alpha),\n",
    "        edgecolors=(0, 0, 0, edge_alpha),\n",
    "        linewidths=0.15,\n",
    "    )\n",
    "    if hasattr(coll, 'set_antialiaseds'):\n",
    "        coll.set_antialiaseds(True)\n",
    "    if hasattr(coll, 'set_zsort'):\n",
    "        coll.set_zsort('min')\n",
    "    ax.add_collection3d(coll)\n",
    "\n",
    "    # Tight limits & view\n",
    "    xmin, xmax = float(np.nanmin(P[:, :, 0])), float(np.nanmax(P[:, :, 0]))\n",
    "    ymin, ymax = float(np.nanmin(P[:, :, 1])), float(np.nanmax(P[:, :, 1]))\n",
    "    zmin, zmax = float(np.nanmin(P[:, :, 2])), float(np.nanmax(P[:, :, 2]))\n",
    "    wx, wy, wz = xmax - xmin, ymax - ymin, max(1e-9, zmax - zmin)\n",
    "    ax.set_xlim(xmin - pad_frac * wx, xmax + pad_frac * wx)\n",
    "    ax.set_ylim(ymin - pad_frac * wy, ymax + pad_frac * wy)\n",
    "    ax.set_zlim(zmin - pad_frac * wz, zmax + pad_frac * wz)\n",
    "    ax.view_init(elev=elev, azim=azim)\n",
    "\n",
    "    return True, scale_km, days, hull_volume_km2_days, hull_surface_km_day\n",
    "\n",
    "# =============================================================================\n",
    "# Per‑event metrics wrapper (for sort/labels consistency)\n",
    "# =============================================================================\n",
    "\n",
    "def _compute_hull_metrics_and_ot(\n",
    "    eg_clean: gpd.GeoDataFrame,\n",
    "    *,\n",
    "    date_col: str = \"date\",\n",
    "    z_col: str = \"event_day\",\n",
    "    n_ring_samples: int = 100,\n",
    "    n_theta: int = 96,\n",
    "    center_each_day: bool = True,\n",
    "    crs_epsg: int = 5070,\n",
    "    ot_grid_res_m: float = 1000.0,\n",
    "    ot_epsilon: float = 2000.0,\n",
    "    ot_n_iter: int = 200,\n",
    "):\n",
    "    \"\"\"Compute hull metrics + OT series for a cleaned event.\n",
    "\n",
    "    Returns (ok, scale_km, days, hull_volume_km2_days, hull_surface_km_day,\n",
    "             sa_to_v_1_per_km, ot_speed_mean, ot_df)\n",
    "    \"\"\"\n",
    "    if eg_clean is None or eg_clean.empty:\n",
    "        return False, np.nan, 0, 0.0, 0.0, np.nan, np.nan, pd.DataFrame()\n",
    "\n",
    "    eg = eg_clean.copy()\n",
    "    eg[date_col] = pd.to_datetime(eg[date_col], errors=\"coerce\")\n",
    "    eg = eg.sort_values(date_col).reset_index(drop=True)\n",
    "    Z = eg[z_col].to_numpy(float) if z_col in eg.columns else np.arange(1, len(eg)+1, float)\n",
    "\n",
    "    if crs_epsg is not None:\n",
    "        try: eg = eg.to_crs(epsg=crs_epsg)\n",
    "        except Exception: pass\n",
    "\n",
    "    rings = []; areas_m2 = []\n",
    "    for g in eg.geometry:\n",
    "        poly = _largest_polygon(g)\n",
    "        if poly is None: continue\n",
    "        areas_m2.append(float(poly.area))\n",
    "        xy = _sample_ring_equal_steps(poly, n_ring_samples)\n",
    "        if xy is None: continue\n",
    "        if center_each_day: xy = xy - xy.mean(axis=0)\n",
    "        rings.append(xy)\n",
    "\n",
    "    if len(rings) < 2:\n",
    "        return False, np.nan, 0, 0.0, 0.0, np.nan, np.nan, pd.DataFrame()\n",
    "\n",
    "    thetas = np.linspace(0, 2*np.pi, n_theta, endpoint=False)\n",
    "    U = np.stack([np.cos(thetas), np.sin(thetas)], axis=1)\n",
    "\n",
    "    # space (max support radius)\n",
    "    Rmax = 0.0\n",
    "    for xy in rings:\n",
    "        dots = (U @ xy.T).max(axis=1)\n",
    "        Rmax = max(Rmax, float(np.nanmax(dots)))\n",
    "    scale_km = Rmax / 1000.0\n",
    "    days = len(rings)\n",
    "\n",
    "    # volume\n",
    "    Z_use = np.array(Z[:days], float)\n",
    "    areas_use = np.array(areas_m2[:days], float)\n",
    "    hull_volume_m2_days = np.trapz(areas_use, Z_use) if len(Z_use) >= 2 else 0.0\n",
    "    hull_volume_km2_days = hull_volume_m2_days / 1e6\n",
    "\n",
    "    # surface from triangles of ruled mesh in (km,km,day)\n",
    "    M, T = len(rings), n_theta\n",
    "    R = np.zeros((M, T), float)\n",
    "    for i, xy in enumerate(rings):\n",
    "        R[i, :] = (U @ xy.T).max(axis=1)\n",
    "    PK = np.zeros((M, T, 3), float)\n",
    "    PK[:, :, 0] = (R * U[None, :, 0]) / 1000.0\n",
    "    PK[:, :, 1] = (R * U[None, :, 1]) / 1000.0\n",
    "    PK[:, :, 2] = np.array(Z[:M], float)[:, None]\n",
    "    surface = 0.0\n",
    "    for i in range(M - 1):\n",
    "        for j in range(T):\n",
    "            jn = (j + 1) % T\n",
    "            v1, v2, v3, v4 = PK[i, j], PK[i, jn], PK[i+1, jn], PK[i+1, j]\n",
    "            surface += _tri_area(v1, v2, v3) + _tri_area(v1, v3, v4)\n",
    "    hull_surface_km_day = float(surface)\n",
    "\n",
    "    sa_to_v = (hull_surface_km_day / hull_volume_km2_days) if hull_volume_km2_days > 0 else np.nan\n",
    "\n",
    "    # OT series + mean speed\n",
    "    ot_df = compute_ot_velocity_series(\n",
    "        eg_clean, crs_epsg=crs_epsg,\n",
    "        grid_res_m=ot_grid_res_m, epsilon=ot_epsilon, n_iter=ot_n_iter\n",
    "    )\n",
    "    ot_mean = float(np.nanmean(ot_df[\"ot_speed_km_per_day\"])) if not ot_df.empty else np.nan\n",
    "\n",
    "    return True, scale_km, days, hull_volume_km2_days, hull_surface_km_day, sa_to_v, ot_mean, ot_df\n",
    "\n",
    "# =============================================================================\n",
    "# Panel builder (minimal, tight layout)\n",
    "# =============================================================================\n",
    "\n",
    "@dataclass\n",
    "class PanelTextStyle:\n",
    "    label_units: bool = False   # show units in labels?\n",
    "    y0: float = 0.36            # starting y (move label block much higher)\n",
    "    dy: float = 0.10            # vertical gap between lines (tighter)\n",
    "    fontsize: int = 6\n",
    "    show_surface_line: bool = False  # optional 5th line (surface)\n",
    "    show_ratio_line: bool = False    # optional 6th line (SA/V)\n",
    "\n",
    "\n",
    "def plot_hull_panel_minimal(\n",
    "    gdf_daily: gpd.GeoDataFrame,\n",
    "    *,\n",
    "    n_rows: int = 10,\n",
    "    n_cols: int = 10,\n",
    "    min_duration: int = 15,\n",
    "    min_area_km2: float = 50,\n",
    "    out_pdf: Optional[str] = None,\n",
    "    out_png: Optional[str] = None,\n",
    "    out_csv: Optional[str] = None,\n",
    "    out_ot_csv: Optional[str] = None,\n",
    "    transparency: bool = True,\n",
    "    tile_in: float = 0.9,\n",
    "    wspace: float = 0.02,\n",
    "    hspace: float = 0.08,\n",
    "    ot_grid_res_m: float = 1000.0,\n",
    "    ot_epsilon: float = 2000.0,\n",
    "    ot_n_iter: int = 200,\n",
    "    order_key: str = \"volume\",  # DEFAULT: sort by volume ascending\n",
    "    text_style: PanelTextStyle = PanelTextStyle(),\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Build a tiled panel of time‑hulls and save PNG/PDF + tables for analysis.\n",
    "\n",
    "    Returns per‑event DataFrame with columns:\n",
    "    id, scale_km, days, hull_volume, hull_surface, sa_to_v, ot_speed_mean\n",
    "    \"\"\"\n",
    "    # Candidate filter\n",
    "    summ = gdf_daily.groupby(\"id\").agg(\n",
    "        duration=(\"duration\", \"first\"),\n",
    "        area=(\"total_area_km2\", \"first\"),\n",
    "    ).reset_index()\n",
    "    cand = summ.query(\"duration >= @min_duration and area >= @min_area_km2\").copy()\n",
    "    ids_all = cand[\"id\"].tolist()\n",
    "    if len(ids_all) == 0:\n",
    "        raise ValueError(\"No events pass the filters; relax thresholds.\")\n",
    "\n",
    "    # Compute metrics + OT per event\n",
    "    items = []\n",
    "    for eid in ids_all:\n",
    "        eg_clean = clean_event_daily_rows(gdf_daily, eid)\n",
    "        ok, scale_km, days, hv, hs, sa_to_v, ot_mean, ot_df = _compute_hull_metrics_and_ot(\n",
    "            eg_clean,\n",
    "            crs_epsg=5070,\n",
    "            ot_grid_res_m=ot_grid_res_m, ot_epsilon=ot_epsilon, ot_n_iter=ot_n_iter,\n",
    "        )\n",
    "        if ok:\n",
    "            items.append({\n",
    "                \"id\": float(eid),\n",
    "                \"eg_clean\": eg_clean,\n",
    "                \"scale_km\": float(scale_km),\n",
    "                \"days\": int(days),\n",
    "                \"hull_volume\": float(hv),\n",
    "                \"hull_surface\": float(hs),\n",
    "                \"sa_to_v\": float(sa_to_v) if np.isfinite(sa_to_v) else np.nan,\n",
    "                \"ot_mean\": float(ot_mean) if np.isfinite(ot_mean) else np.nan,\n",
    "                \"ot_df\": ot_df.assign(id=float(eid)) if out_ot_csv else None,\n",
    "            })\n",
    "\n",
    "    if not items:\n",
    "        raise ValueError(\"No events produced valid hull metrics after cleaning.\")\n",
    "\n",
    "    # Sorting\n",
    "    if order_key == \"days_then_volume\":\n",
    "        items.sort(key=lambda d: (d[\"days\"], d[\"hull_volume\"]))\n",
    "    elif order_key == \"days\":\n",
    "        items.sort(key=lambda d: d[\"days\"])  # rare use\n",
    "    else:  # \"volume\" (default)\n",
    "        items.sort(key=lambda d: d[\"hull_volume\"])  # pure volume ascending\n",
    "\n",
    "    # Limit to grid capacity\n",
    "    total_slots = n_rows * n_cols\n",
    "    items = items[:total_slots]\n",
    "\n",
    "    rows_tbl = []\n",
    "    ot_long_rows = []\n",
    "\n",
    "    def _make_figure():\n",
    "        fig = plt.figure(figsize=(n_cols * tile_in, n_rows * tile_in))\n",
    "        if transparency: fig.patch.set_alpha(0)\n",
    "        return fig\n",
    "\n",
    "    def _setup_axes(fig):\n",
    "        axes = np.empty((n_rows, n_cols), dtype=object)\n",
    "        for r in range(n_rows):\n",
    "            for c in range(n_cols):\n",
    "                ax = fig.add_subplot(n_rows, n_cols, r * n_cols + c + 1, projection=\"3d\")\n",
    "                if transparency:\n",
    "                    try:\n",
    "                        ax.set_facecolor(\"none\")\n",
    "                        ax.xaxis.pane.set_alpha(0.0)\n",
    "                        ax.yaxis.pane.set_alpha(0.0)\n",
    "                        ax.zaxis.pane.set_alpha(0.0)\n",
    "                    except Exception:\n",
    "                        pass\n",
    "                axes[r, c] = ax\n",
    "        return axes\n",
    "\n",
    "    def _place_index(k: int) -> Tuple[int, int]:\n",
    "        return k // n_cols, k % n_cols\n",
    "\n",
    "    def _fmt_line(label: str, value: str, with_units: bool, units: str) -> str:\n",
    "        return f\"{label} {value} {units}\" if with_units else f\"{label} {value}\"\n",
    "\n",
    "    def _annotate(ax, scale_km: float, days: int, hv: float, hs: float, sa_to_v: float, ot_mean: float):\n",
    "        y0, dy, fs, with_units = text_style.y0, text_style.dy, text_style.fontsize, text_style.label_units\n",
    "        line = 0\n",
    "        # 1) volume\n",
    "        ax.text2D(0.5, y0 - line*dy, _fmt_line(\"volume\", f\"{hv:.0f}\", with_units, \"km²·days\"),\n",
    "                  transform=ax.transAxes, ha='center', va='top', fontsize=fs); line += 1\n",
    "        # 2) OT speed (placeholder dash if NaN)\n",
    "        v_txt = f\"{ot_mean:.2f}\" if np.isfinite(ot_mean) else \"—\"\n",
    "        ax.text2D(0.5, y0 - line*dy, _fmt_line(\"OT v̄\", v_txt, with_units, \"km/day\"),\n",
    "                  transform=ax.transAxes, ha='center', va='top', fontsize=fs); line += 1\n",
    "        # 3) space\n",
    "        ax.text2D(0.5, y0 - line*dy, _fmt_line(\"space\", f\"{scale_km:.1f}\", with_units, \"km\"),\n",
    "                  transform=ax.transAxes, ha='center', va='top', fontsize=fs); line += 1\n",
    "        # 4) time\n",
    "        ax.text2D(0.5, y0 - line*dy, _fmt_line(\"time\", f\"{days:d}\", with_units, \"days\"),\n",
    "                  transform=ax.transAxes, ha='center', va='top', fontsize=fs)\n",
    "\n",
    "    def _draw_page(page_items):\n",
    "        fig = _make_figure(); axes = _setup_axes(fig)\n",
    "        for k, item in enumerate(page_items):\n",
    "            r, c = _place_index(k); ax = axes[r, c]\n",
    "            ok, scale_km, days, hv, hs = draw_ruled_time_hull_minimal(ax, item[\"eg_clean\"])  # draw & metrics\n",
    "            if not ok:\n",
    "                ax.set_axis_off(); continue\n",
    "            _annotate(ax, scale_km, days, hv, hs, item[\"sa_to_v\"], item[\"ot_mean\"])\n",
    "            rows_tbl.append({\n",
    "                \"id\": item[\"id\"],\n",
    "                \"scale_km\": scale_km,\n",
    "                \"days\": days,\n",
    "                \"hull_volume\": hv,\n",
    "                \"hull_surface\": hs,\n",
    "                \"sa_to_v\": item[\"sa_to_v\"],\n",
    "                \"ot_speed_mean\": item[\"ot_mean\"],\n",
    "            })\n",
    "            if out_ot_csv and item[\"ot_df\"] is not None and not item[\"ot_df\"].empty:\n",
    "                ot_long_rows.append(item[\"ot_df\"][\n",
    "                    [\"id\",\"t0\",\"t1\",\"day0\",\"day1\",\"ot_w2_km2\",\"ot_speed_km_per_day\"]\n",
    "                ])\n",
    "        plt.subplots_adjust(left=0.01, right=0.99, bottom=0.02, top=0.98,\n",
    "                            wspace=wspace, hspace=hspace)\n",
    "        return fig\n",
    "\n",
    "    # Render + save (both PDF and PNG if requested)\n",
    "    page_size = n_rows * n_cols\n",
    "    if out_pdf:\n",
    "        with PdfPages(out_pdf) as pdf:\n",
    "            for start in range(0, len(items), page_size):\n",
    "                fig = _draw_page(items[start:start + page_size])\n",
    "                pdf.savefig(fig, transparent=True)\n",
    "                if out_png:\n",
    "                    # Save PNG of this page before closing\n",
    "                    idx = start // page_size + 1\n",
    "                    fname = out_png if len(items) <= page_size else out_png.replace(\".png\", f\"_{idx}.png\")\n",
    "                    fig.savefig(fname, dpi=300, transparent=True)\n",
    "                    print(f\"Saved PNG panel to {fname}\")\n",
    "                plt.close(fig)\n",
    "        print(f\"Wrote panel(s) to {out_pdf}\")\n",
    "    else:\n",
    "        # Single page render\n",
    "        fig = _draw_page(items)\n",
    "        if out_png:\n",
    "            fig.savefig(out_png, dpi=300, transparent=True)\n",
    "            print(f\"Saved PNG panel to {out_png}\")\n",
    "        plt.close(fig)\n",
    "\n",
    "    # Tables (ordered to match display)\n",
    "    if order_key == \"days_then_volume\":\n",
    "        sort_cols = [\"days\", \"hull_volume\"]\n",
    "    elif order_key == \"days\":\n",
    "        sort_cols = [\"days\"]\n",
    "    else:\n",
    "        sort_cols = [\"hull_volume\"]\n",
    "\n",
    "    df = pd.DataFrame(rows_tbl, columns=[\n",
    "        \"id\",\"scale_km\",\"days\",\"hull_volume\",\"hull_surface\",\"sa_to_v\",\"ot_speed_mean\"\n",
    "    ]).sort_values(sort_cols, ascending=[True]*len(sort_cols))\n",
    "\n",
    "    if out_csv:\n",
    "        df.to_csv(out_csv, index=False)\n",
    "        print(f\"Saved summary table to {out_csv}\")\n",
    "\n",
    "    if out_ot_csv and len(ot_long_rows):\n",
    "        ot_long = pd.concat(ot_long_rows, ignore_index=True)\n",
    "        ot_long.to_csv(out_ot_csv, index=False)\n",
    "        print(f\"Saved per-interval OT series to {out_ot_csv}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "# =============================================================================\n",
    "# Convenience wrapper for \"just run it\" style\n",
    "# =============================================================================\n",
    "\n",
    "def run_fired_panel(\n",
    "    gdf_daily: gpd.GeoDataFrame,\n",
    "    *,\n",
    "    out_pdf: Optional[str] = \"hull_panels.pdf\",\n",
    "    out_png: Optional[str] = \"hull_panels.png\",\n",
    "    out_csv: Optional[str] = \"hull_summary.csv\",\n",
    "    out_ot_csv: Optional[str] = \"hull_ot_series.csv\",\n",
    "    **kwargs,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"One‑call convenience wrapper using volume sorting and compact labels.\"\"\"\n",
    "    return plot_hull_panel_minimal(\n",
    "        gdf_daily,\n",
    "        out_pdf=out_pdf,\n",
    "        out_png=out_png,\n",
    "        out_csv=out_csv,\n",
    "        out_ot_csv=out_ot_csv,\n",
    "        order_key=\"volume\",\n",
    "        text_style=PanelTextStyle(label_units=False, y0=0.36, dy=0.10, fontsize=6,\n",
    "                                  show_surface_line=False, show_ratio_line=False),\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "# =============================================================================\n",
    "# __main__ example (expects a GeoDataFrame named `gdfd` in scope)\n",
    "# =============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        summary = run_fired_panel(\n",
    "            gdfd,  # replace with your FIRED daily GeoDataFrame\n",
    "            n_rows=8, n_cols=8,\n",
    "            min_duration=20, min_area_km2=80,\n",
    "        )\n",
    "        print(summary.head())\n",
    "    except NameError:\n",
    "        print(\"Define 'gdfd' (FIRED daily GeoDataFrame) before running as a script.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
